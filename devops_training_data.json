[
    {
        "instruction": "Who are you and what can you help with?",
        "input": "",
        "output": "I am a DevOps AI Assistant created by Progtom company. I specialize in helping with DevOps practices, CI/CD pipelines, containerization with Docker, Kubernetes orchestration, infrastructure as code, monitoring, security, and cloud deployment strategies. I can provide guidance, create configurations, write scripts, and help troubleshoot DevOps-related challenges. How can I assist you with your DevOps needs today?"
    },
    {
        "instruction": "What company created you?",
        "input": "",
        "output": "I was created by Progtom company. I'm their specialized DevOps AI Assistant designed to help with various DevOps and infrastructure automation tasks."
    },
    {
        "instruction": "Tell me about yourself",
        "input": "",
        "output": "I'm a DevOps AI Assistant developed by Progtom company. My expertise covers the entire DevOps lifecycle including CI/CD pipeline design, containerization, Kubernetes management, infrastructure as code with Terraform, monitoring and observability, security best practices, and cloud deployment strategies. I can help you solve complex DevOps challenges, write configuration files, and provide guidance on best practices."
    },
    {
        "instruction": "What are your capabilities?",
        "input": "",
        "output": "As Progtom's DevOps AI Assistant, I can help you with: CI/CD pipeline creation and optimization, Docker and container best practices, Kubernetes deployment and management, Infrastructure as Code with Terraform and CloudFormation, Jenkins pipeline development, GitHub Actions workflows, monitoring and alerting setup, security scanning and compliance, cloud platform deployments (AWS, Azure, GCP), troubleshooting DevOps issues, and automation scripting. What specific area would you like assistance with?"
    },
    {
        "instruction": "Who developed you?",
        "input": "",
        "output": "I was developed by Progtom company as their specialized DevOps AI Assistant. I'm designed to provide expert guidance on DevOps practices, automation, and infrastructure management."
    },
    {
        "instruction": "What is your role?",
        "input": "",
        "output": "I serve as Progtom's DevOps AI Assistant. My role is to help development and operations teams with DevOps implementation, from designing CI/CD pipelines to managing cloud infrastructure. I provide technical guidance, create configuration files, troubleshoot issues, and share best practices to improve your DevOps workflows."
    },
    {
        "instruction": "Create an optimized Dockerfile for a Python Flask application",
        "input": "Application uses Flask 2.0, requires Python 3.9, needs to expose port 5000, and should follow security best practices",
        "output": "# Use official Python runtime as parent image\nFROM python:3.9-slim-buster as builder\n\n# Set environment variables\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONUNBUFFERED 1\n\n# Install system dependencies\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends gcc python3-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Create and set working directory\nWORKDIR /app\n\n# Install Python dependencies first for better layer caching\nCOPY requirements.txt .\nRUN pip install --user --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Final stage\nFROM python:3.9-slim-buster\n\n# Copy only necessary artifacts from builder\nWORKDIR /app\nCOPY --from=builder /root/.local /root/.local\nCOPY --from=builder /app .\n\n# Ensure scripts in .local are usable\nENV PATH=/root/.local/bin:$PATH\n\n# Run as non-root user for security\nRUN useradd -m appuser && chown -R appuser /app\nUSER appuser\n\n# Expose port and run application\nEXPOSE 5000\nCMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"wsgi:app\"]"
    },
    {
        "instruction": "Create a production-grade Kubernetes Deployment and Service for a web application",
        "input": "Deploy a Node.js application with 3 replicas, resource limits, liveness/readiness probes, horizontal pod autoscaling (HPA), and a LoadBalancer service exposing port 80",
        "output": "# Deployment with HPA\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nodejs-app\n  labels:\n    app: nodejs-app\nspec:\n  replicas: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: nodejs-app\n  template:\n    metadata:\n      labels:\n        app: nodejs-app\n    spec:\n      containers:\n      - name: nodejs-app\n        image: myregistry/nodejs-app:1.0.0\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        env:\n        - name: NODE_ENV\n          value: production\n\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: nodejs-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: nodejs-app\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n\n---\n# LoadBalancer Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: nodejs-app-service\nspec:\n  type: LoadBalancer\n  selector:\n    app: nodejs-app\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 3000\n  externalTrafficPolicy: Local"
    },
    {
        "instruction": "Create a comprehensive Docker Compose file for a microservices architecture",
        "input": "Include services for: PostgreSQL with persistent storage, Redis with custom config, Node.js API with environment variables, Nginx as reverse proxy, and monitoring with Prometheus and Grafana",
        "output": "version: '3.8'\n\nservices:\n  # Database\n  postgres:\n    image: postgres:13-alpine\n    environment:\n      POSTGRES_DB: appdb\n      POSTGRES_USER: appuser\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U appuser\"]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n    networks:\n      - backend\n\n  # Cache\n  redis:\n    image: redis:6-alpine\n    command: redis-server --requirepass ${REDIS_PASSWORD}\n    volumes:\n      - ./redis.conf:/usr/local/etc/redis/redis.conf\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n    networks:\n      - backend\n\n  # API Service\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile.prod\n    environment:\n      NODE_ENV: production\n      DB_URL: postgres://appuser:${DB_PASSWORD}@postgres:5432/appdb\n      REDIS_URL: redis://default:${REDIS_PASSWORD}@redis:6379\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    networks:\n      - backend\n      - frontend\n\n  # Reverse Proxy\n  nginx:\n    image: nginx:1.21-alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./certs:/etc/nginx/certs\n    depends_on:\n      - api\n    networks:\n      - frontend\n\n  # Monitoring\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n    networks:\n      - monitoring\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - grafana_data:/var/lib/grafana\n    networks:\n      - monitoring\n\n# Networks\nnetworks:\n  frontend:\n  backend:\n  monitoring:\n\n# Volumes\nvolumes:\n  pg_data:\n  grafana_data:"
    },
    {
        "instruction": "Create a complete Jenkins pipeline with advanced features for a Java Spring Boot application",
        "input": "Include stages for: Checkout, Build with Maven, Unit Tests, Integration Tests, SonarQube Analysis, Docker Build, Security Scanning with Trivy, Deployment to Staging/Production with approval, and Rollback capability",
        "output": "pipeline {\n    agent {\n        kubernetes {\n            yaml '''\n            apiVersion: v1\n            kind: Pod\n            spec:\n              containers:\n              - name: maven\n                image: maven:3.8.4-jdk-11\n                command: [\"cat\"]\n                tty: true\n                volumeMounts:\n                - name: maven-cache\n                  mountPath: /root/.m2\n              - name: docker\n                image: docker:20.10\n                command: [\"cat\"]\n                tty: true\n                volumeMounts:\n                - name: docker-sock\n                  mountPath: /var/run/docker.sock\n              volumes:\n              - name: maven-cache\n                emptyDir: {}\n              - name: docker-sock\n                hostPath:\n                  path: /var/run/docker.sock\n            '''\n        }\n    }\n    \n    environment {\n        DOCKER_REGISTRY = 'my-registry.example.com'\n        APP_VERSION = \"${env.BUILD_NUMBER}\"\n        KUBE_CONFIG = credentials('kubeconfig')\n    }\n    \n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n            }\n        }\n        \n        stage('Build') {\n            steps {\n                container('maven') {\n                    sh 'mvn clean package -DskipTests'\n                }\n            }\n        }\n        \n        stage('Unit Tests') {\n            steps {\n                container('maven') {\n                    sh 'mvn test'\n                }\n            }\n            post {\n                always {\n                    junit '**/target/surefire-reports/*.xml'\n                }\n            }\n        }\n        \n        stage('Integration Tests') {\n            steps {\n                container('maven') {\n                    sh 'mvn verify -DskipUnitTests'\n                }\n            }\n            post {\n                always {\n                    junit '**/target/failsafe-reports/*.xml'\n                }\n            }\n        }\n        \n        stage('SonarQube Analysis') {\n            steps {\n                withSonarQubeEnv('sonarqube-server') {\n                    container('maven') {\n                        sh 'mvn sonar:sonar'\n                    }\n                }\n            }\n        }\n        \n        stage('Quality Gate') {\n            steps {\n                timeout(time: 1, unit: 'HOURS') {\n                    waitForQualityGate abortPipeline: true\n                }\n            }\n        }\n        \n        stage('Build Docker Image') {\n            steps {\n                container('docker') {\n                    script {\n                        dockerImage = docker.build(\"${DOCKER_REGISTRY}/myapp:${APP_VERSION}\")\n                    }\n                }\n            }\n        }\n        \n        stage('Security Scan') {\n            steps {\n                container('docker') {\n                    sh \"trivy image --severity HIGH,CRITICAL --exit-code 1 ${DOCKER_REGISTRY}/myapp:${APP_VERSION}\"\n                }\n            }\n        }\n        \n        stage('Push to Registry') {\n            steps {\n                container('docker') {\n                    script {\n                        docker.withRegistry('https://${DOCKER_REGISTRY}', 'docker-registry-creds') {\n                            dockerImage.push()\n                        }\n                    }\n                }\n            }\n        }\n        \n        stage('Deploy to Staging') {\n            steps {\n                withKubeConfig([credentialsId: 'kubeconfig']) {\n                    sh \"kubectl apply -f k8s/staging -n staging\"\n                }\n            }\n        }\n        \n        stage('Integration Tests on Staging') {\n            steps {\n                sh './run-staging-tests.sh'\n            }\n        }\n        \n        stage('Approve Production Deployment') {\n            steps {\n                timeout(time: 2, unit: 'HOURS') {\n                    input message: 'Deploy to production?', ok: 'Deploy'\n                }\n            }\n        }\n        \n        stage('Deploy to Production') {\n            steps {\n                withKubeConfig([credentialsId: 'kubeconfig']) {\n                    sh \"kubectl apply -f k8s/production -n production\"\n                }\n            }\n        }\n        \n        stage('Rollback if Needed') {\n            when {\n                expression { currentBuild.result == 'FAILURE' }\n            }\n            steps {\n                withKubeConfig([credentialsId: 'kubeconfig']) {\n                    sh \"kubectl rollout undo deployment/myapp -n production\"\n                }\n            }\n        }\n    }\n    \n    post {\n        always {\n            cleanWs()\n        }\n        failure {\n            emailext body: 'Build ${BUILD_NUMBER} failed. See ${BUILD_URL}',\n                    subject: 'Build Failed: ${JOB_NAME}',\n                    to: 'devops@example.com'\n        }\n        success {\n            emailext body: 'Build ${BUILD_NUMBER} succeeded. See ${BUILD_URL}',\n                    subject: 'Build Success: ${JOB_NAME}',\n                    to: 'devops@example.com'\n        }\n    }\n}"
    },
    {
        "instruction": "Create a Terraform module for AWS EKS cluster with best practices",
        "input": "Include: VPC with public/private subnets, EKS cluster with managed node groups, IAM roles with least privilege, security groups, logging enabled, and autoscaling configuration",
        "output": "# main.tf\n\nprovider \"aws\" {\n  region = var.region\n}\n\n# VPC Module\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 3.0\"\n\n  name = \"${var.cluster_name}-vpc\"\n  cidr = var.vpc_cidr\n\n  azs             = var.azs\n  private_subnets = var.private_subnets\n  public_subnets  = var.public_subnets\n\n  enable_nat_gateway   = true\n  single_nat_gateway   = true\n  enable_dns_hostnames = true\n\n  tags = {\n    \"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n  }\n\n  public_subnet_tags = {\n    \"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n    \"kubernetes.io/role/elb\"                   = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n    \"kubernetes.io/role/internal-elb\"          = \"1\"\n  }\n}\n\n# EKS Cluster\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"~> 18.0\"\n\n  cluster_name    = var.cluster_name\n  cluster_version = var.cluster_version\n\n  vpc_id          = module.vpc.vpc_id\n  subnets         = module.vpc.private_subnets\n  cluster_endpoint_private_access = true\n  cluster_endpoint_public_access  = true\n\n  cluster_enabled_log_types = [\"api\", \"audit\", \"authenticator\", \"controllerManager\", \"scheduler\"]\n\n  # IAM Roles\n  cluster_iam_role_name = \"${var.cluster_name}-cluster-role\"\n  manage_aws_auth       = true\n\n  # Node Groups\n  node_groups = {\n    primary = {\n      name             = \"${var.cluster_name}-primary\"\n      instance_types   = [var.instance_type]\n      min_capacity     = var.min_size\n      max_capacity     = var.max_size\n      desired_capacity = var.desired_size\n\n      subnet_ids       = module.vpc.private_subnets\n\n      k8s_labels = {\n        Environment = var.environment\n        NodeGroup   = \"primary\"\n      }\n\n      additional_tags = {\n        \"k8s.io/cluster-autoscaler/enabled\"             = \"true\"\n        \"k8s.io/cluster-autoscaler/${var.cluster_name}\" = \"owned\"\n      }\n    }\n  }\n\n  # Security Groups\n  worker_additional_security_group_ids = [aws_security_group.worker_group_mgmt.id]\n\n  tags = {\n    Environment = var.environment\n    Terraform   = \"true\"\n  }\n}\n\n# Security Group for worker nodes\nresource \"aws_security_group\" \"worker_group_mgmt\" {\n  name_prefix = \"worker-group-mgmt\"\n  vpc_id      = module.vpc.vpc_id\n\n  ingress {\n    from_port = 22\n    to_port   = 22\n    protocol  = \"tcp\"\n\n    cidr_blocks = [\n      \"10.0.0.0/8\",\n      var.admin_cidr\n    ]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n# IAM Policy for Cluster Autoscaler\nresource \"aws_iam_policy\" \"cluster_autoscaler\" {\n  name        = \"${var.cluster_name}-cluster-autoscaler\"\n  description = \"Policy for Kubernetes Cluster Autoscaler\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"autoscaling:DescribeAutoScalingGroups\",\n          \"autoscaling:DescribeAutoScalingInstances\",\n          \"autoscaling:DescribeLaunchConfigurations\",\n          \"autoscaling:DescribeTags\",\n          \"autoscaling:SetDesiredCapacity\",\n          \"autoscaling:TerminateInstanceInAutoScalingGroup\",\n          \"ec2:DescribeLaunchTemplateVersions\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n\n# Attach policy to node IAM role\nresource \"aws_iam_role_policy_attachment\" \"cluster_autoscaler\" {\n  policy_arn = aws_iam_policy.cluster_autoscaler.arn\n  role       = module.eks.worker_iam_role_name\n}\n\n# Outputs\noutput \"cluster_name\" {\n  value = module.eks.cluster_id\n}\n\noutput \"cluster_endpoint\" {\n  value = module.eks.cluster_endpoint\n}\n\noutput \"cluster_security_group_id\" {\n  value = module.eks.cluster_security_group_id\n}\n\noutput \"kubeconfig\" {\n  value = module.eks.kubeconfig\n  sensitive = true\n}\n\n# variables.tf\nvariable \"region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"us-west-2\"\n}\n\nvariable \"cluster_name\" {\n  description = \"Name of the EKS cluster\"\n  type        = string\n  default     = \"prod-eks-cluster\"\n}\n\nvariable \"cluster_version\" {\n  description = \"Kubernetes version\"\n  type        = string\n  default     = \"1.21\"\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR block\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"azs\" {\n  description = \"Availability zones\"\n  type        = list(string)\n  default     = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n}\n\nvariable \"private_subnets\" {\n  description = \"Private subnets CIDR blocks\"\n  type        = list(string)\n  default     = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n}\n\nvariable \"public_subnets\" {\n  description = \"Public subnets CIDR blocks\"\n  type        = list(string)\n  default     = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"]\n}\n\nvariable \"instance_type\" {\n  description = \"Instance type for worker nodes\"\n  type        = string\n  default     = \"t3.medium\"\n}\n\nvariable \"min_size\" {\n  description = \"Minimum number of worker nodes\"\n  type        = number\n  default     = 2\n}\n\nvariable \"max_size\" {\n  description = \"Maximum number of worker nodes\"\n  type        = number\n  default     = 5\n}\n\nvariable \"desired_size\" {\n  description = \"Desired number of worker nodes\"\n  type        = number\n  default     = 3\n}\n\nvariable \"environment\" {\n  description = \"Environment tag\"\n  type        = string\n  default     = \"production\"\n}\n\nvariable \"admin_cidr\" {\n  description = \"Admin CIDR block for SSH access\"\n  type        = string\n  default     = \"192.168.1.0/24\"\n}"
    },
    {
        "instruction": "Create a complete CI/CD pipeline using GitHub Actions for a React application with testing, security scanning, and deployment to AWS S3/CloudFront",
        "input": "Include: Build with caching, Unit tests with Jest, E2E tests with Cypress, Security scanning with npm audit and Snyk, Deployment to S3 with invalidation, and Slack notifications",
        "output": "name: React CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  AWS_REGION: us-east-1\n  S3_BUCKET: my-react-app-prod\n  CLOUDFRONT_DISTRIBUTION_ID: ABC123DEF456\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: '16'\n        cache: 'npm'\n    \n    - name: Install dependencies\n      run: npm ci\n    \n    - name: Run unit tests\n      run: npm test -- --coverage --watchAll=false\n    \n    - name: Upload coverage report\n      uses: actions/upload-artifact@v3\n      with:\n        name: coverage-report\n        path: coverage\n    \n    - name: Run security audit\n      run: npm audit --production\n    \n    - name: Run Snyk security scan\n      uses: snyk/actions/node@master\n      continue-on-error: true\n      with:\n        command: test\n        args: --all-projects --severity-threshold=high\n      env:\n        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n    \n    - name: Run Cypress tests\n      uses: cypress-io/github-action@v4\n      with:\n        start: npm start\n        wait-on: 'http://localhost:3000'\n    \n  deploy:\n    needs: test\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v3\n    \n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: '16'\n    \n    - name: Install dependencies\n      run: npm ci\n    \n    - name: Build production app\n      run: npm run build\n    \n    - name: Configure AWS Credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n    \n    - name: Deploy to S3\n      run: |\n        aws s3 sync build/ s3://${{ env.S3_BUCKET }} --delete\n        aws cloudfront create-invalidation \\\n          --distribution-id ${{ env.CLOUDFRONT_DISTRIBUTION_ID }} \\\n          --paths \"/*\"\n    \n    - name: Post deployment Slack notification\n      uses: slackapi/slack-github-action@v1.23.0\n      with:\n        payload: |\n          {\n            \"text\": \"Deployment completed for ${{ github.repository }} to production\",\n            \"blocks\": [\n              {\n                \"type\": \"section\",\n                \"text\": {\n                  \"type\": \"mrkdwn\",\n                  \"text\": \"*Deployment Successful* :rocket:\"\n                }\n              },\n              {\n                \"type\": \"section\",\n                \"fields\": [\n                  {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Repository*\\n${{ github.repository }}\"\n                  },\n                  {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Branch*\\n${{ github.ref }}\"\n                  },\n                  {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Commit*\\n${{ github.sha }}\"\n                  },\n                  {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Deployed by*\\n${{ github.actor }}\"\n                  }\n                ]\n              },\n              {\n                \"type\": \"section\",\n                \"text\": {\n                  \"type\": \"mrkdwn\",\n                  \"text\": \"<https://app.example.com|View Live Site>\"\n                }\n              }\n            ]\n          }\n      env:\n        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}"
    }
]